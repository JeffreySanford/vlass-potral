# VLASS Portal: Scientific Operations Platform for Radio Astronomy

## Marketing Overview & Product Vision

**Version:** 1.0  
**Date:** February 2026  
**Status:** Active (MVP Complete, Phases 2‚Äì3 Planning)

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [The Problem](#the-problem)
3. [The Solution](#the-solution)
4. [Product Overview](#product-overview)
5. [MVP Achievements](#mvp-achievements)
6. [Phase 2: AI Integration Foundation](#phase-2-ai-integration-foundation)
7. [Phase 3: CosmicAI Federation & ngVLA Preparation](#phase-3-cosmicai-federation--ngvla-preparation)
8. [Technical Architecture](#technical-architecture)
9. [Strategic Alignment & Impact](#strategic-alignment--impact)
10. [Funding & Investment Model](#funding--investment-model)
11. [Competitive Advantages](#competitive-advantages)
12. [Timeline & Roadmap](#timeline--roadmap)
13. [Call to Action](#call-to-action)

---

## Executive Summary

**VLASS Portal** is an open-source, web-native scientific operations platform for radio astronomy. It provides researchers with fast, intuitive access to massive astronomical datasets (VLASS), powerful tools for AI-assisted analysis, and infrastructure for publishing reproducible scientific findings.

### What It Does (In One Sentence)

> VLASS Portal transforms how radio astronomers explore, analyze, and share discoveries from the Very Large Array Sky Survey‚Äîcombining instant visualization, AI-driven insights, collaborative notebooks, and reproducible research workflows in a single web application.

### The Vision

**Build the missing layer between cutting-edge ML research and operational scientific discovery:**

- **Today's problem:** Radio astronomy researchers have state-of-the-art AI models and petaflops of compute, but interact through Jupyter notebooks (2012-era UX). There's no unified platform for orchestrating, auditing, and publishing AI-assisted analysis.

- **VLASS Portal's solution:** A modern web platform that brings world-class data exploration, AI orchestration, reproducibility, and scientific publishing into a single, intuitive interface.

- **Strategic opportunity:** Position VLASS Portal as the control plane for the NSF-Simons CosmicAI Initiative and the operational backbone for the upcoming ngVLA (Next Generation Very Large Array) facility.

### The Numbers

| Metric | Value | Significance |
| --- | --- | --- |
| **MVP Completion** | 3 major pillars | Ready for operations and community launch |
| **Phase 2 Timeline** | 12‚Äì16 weeks | AI inference + reproducibility foundation |
| **Phase 3 Timeline** | 16‚Äì20 weeks | Multi-site federation + TACC integration |
| **Total Investment** | $300K‚Äì$600K | 2‚Äì3 year path to national infrastructure |
| **Target Users** | 15+ institutions | NSF-affiliated research centers |
| **Strategic Partners** | CosmicAI, NRAO, TACC | Decades-long facilities and initiatives |

---

## The Problem

### Radio Astronomy Data Explosion

The Very Large Array (VLA) and next-generation facilities produce **petabytes of data annually**, but the astronomer's experience of accessing and analyzing that data remains fragmented:

```mermaid
graph LR
    A["Petabytes of<br/>VLASS Data"] -->|"HiPS tiles,<br/>FITS files"| B["Separate<br/>Tools"]
    B --> C["Tool 1:<br/>Aladin Viewer<br/>(desktop)"]
    B --> D["Tool 2:<br/>Python<br/>Notebooks<br/>(Jupyter)"]
    B --> E["Tool 3:<br/>Custom<br/>Scripts<br/>(bash/CLI)"]
    B --> F["Tool 4:<br/>Email<br/>Collaboration<br/>(fragmented)"]
    
    C --> G{{"Researcher<br/>Struggles<br/>With"}}
    D --> G
    E --> G
    F --> G
    
    G -->|"Context switching"| H["Low productivity"]
    G -->|"No audit trail"| I["Reproducibility crisis"]
    G -->|"Manual sharing"| J["Publication delays"]
```

**[VISUAL SPECIFICATION: Replace above diagram with professional infographic showing:]**
- **Left side:** Data volume icons (VLASS, ALMA, ngVLA scales)
- **Center:** Fragmented tool ecosystem (Aladin, IPython, Bash, Email)
- **Right side:** Researcher pain points (context switching, no reproducibility, slow collaboration)
- **Color-code:** Red for problems, green for desired state

### The CosmicAI Gap

The NSF-Simons CosmicAI Initiative is producing breakthrough algorithms:

- **Calibration anomaly detection** (Eric Murphy, NSF NRAO)
- **AlphaCal autonomous interferometric processing** (production-ready)
- **Hyperspectral event detection** via transfer learning (Ce-Ci Xue)
- **Radio image reconstruction** neural networks (Omkar Bait)

**But:** These models live in GitHub repositories and JupyterHub notebooks. They lack:
- Enterprise-grade operational UI
- Reproducibility frameworks
- Governance and audit trails
- Published workflows

### The ngVLA Challenge (2030s)

The Next Generation Very Large Array will deliver:

- **244 antennas**, each 18 meters in diameter
- **Frequencies:** 1.2 GHz to 116 GHz
- **Sensitivity:** 10√ó greater than current VLA
- **Data rate:** ~50 petabytes *per year*
- **Compute requirement:** **50 petaFLOPS** (100√ó current!)

**The reality:** Astronomers will need real-time operational dashboards, not notebooks. A platform that doesn't exist today.

---

## The Solution

### VLASS Portal: Three Pillars (MVP to Phase 3)

```mermaid
%%{init: {"themeVariables":{"fontSize":"22px"},"flowchart":{"nodeSpacing":70,"rankSpacing":90,"padding":24}} }%%
graph TB
    subgraph MVP["MVP (Complete)"]
        MVP1["Pillar 1:<br/>Instant<br/>Performance"]
        MVP2["Pillar 2:<br/>Viewer &<br/>Sharing"]
        MVP3["Pillar 3:<br/>Community<br/>Notebooks"]
    end
    
    subgraph P2["Phase 2 (12-16 weeks)"]
        P2A["Pillar 1:<br/>AI Inference<br/>Service"]
        P2B["Pillar 2:<br/>Job<br/>Orchestration"]
        P2C["Pillar 3:<br/>Reproducibility<br/>Framework"]
        P2D["Pillar 4:<br/>Explainability<br/>UI"]
    end
    
    subgraph P3["Phase 3 (16-20 weeks)"]
        P3A["Pillar 1:<br/>Dataset<br/>Federation"]
        P3B["Pillar 2:<br/>TACC<br/>Integration"]
        P3C["Pillar 3:<br/>Multi-site<br/>Reproducibility"]
        P3D["Pillar 4:<br/>Explanation<br/>Aggregation"]
    end
    
    MVP1 --> P2A
    MVP2 --> P2B
    MVP3 --> P2C
    P2A --> P3A
    P2B --> P3B
    P2C --> P3C
    P2D --> P3D
```

**[VISUAL SPECIFICATION: Professional pyramid or progression diagram showing:]**
- **Base (MVP):** Three pillars with icons (speed, viewer, notebooks)
- **Middle (Phase 2):** Four expansion pillars (inference, jobs, reproducibility, explainability)
- **Top (Phase 3):** Federation and distribution (multi-site, TACC)
- **Animated arrows** showing evolution and capability stacking

---

## Product Overview

### MVP: Three Core Pillars (Completed)

#### **Pillar 1: Instant SSR First Paint** ‚ö°

Users arrive and see a stunning, personalized VLASS sky preview in under **1 second**.

**Features:**
- Server-side rendering (SSR) of regional VLASS imagery
- Opt-in, privacy-conscious location detection (5km geohash precision)
- FCP (First Contentful Paint) <1s on 4G
- LCP (Largest Contentful Paint) <2s
- Mobile + desktop optimized

**Why it matters:** First impression is everything. Users feel the product is fast and responsive *before* any JavaScript loads.

---

#### **Pillar 2: Viewer + Permalinks + Snapshots** üî≠

Seamless sky exploration with shareable links and persistent snapshots.

**Features:**
- **Aladin viewer integration** (Mode A): pan, zoom, multi-layer overlays
- **ViewerState serialization**: exact view encoded as `/view?state=<hash>` or `/view/<shortid>`
- **Snapshot capture**: PNG export of current view with metadata
- **Permalink sharing**: Share exact coordinates + zoom with colleagues
- **FITS cutout download**: Rate-limited, audited science data export

**Use case:** Researcher spots interesting anomaly, captures snapshot, shares link with team. Team member loads exact view, adds annotation, publishes to community.

---

#### **Pillar 3: Community Research Notebooks** üìì

Collaborative, version-controlled research publishing with embedded visualizations.

**Features:**
- **Markdown editor** with embedded viewer blocks (e.g., `\`\`\`viewer { ... }\`\`\``)
- **Auto-snapshotting**: viewer blocks auto-render PNG previews on publish
- **Revision history & diffs**: track every edit, see what changed
- **Moderation controls**: hide/lock/flag inappropriate content
- **Tag system**: user-suggested, moderator-approved topic tags
- **Feed view**: discover research from your community
- **Public read, verified write**: anyone reads, authenticated users publish

**Why it matters:** Closes the loop between exploration (Pillar 2) and publishing. No context-switching to Medium, WordPress, or email.

---

### MVP Architecture: Lightweight, Auditable, Fast

```mermaid
graph TB
    subgraph User["User Experience Layer"]
        W["Angular SSR<br/>web app"]
        A["Aladin Viewer<br/>(Mode A only)"]
    end
    
    subgraph Backend["Backend Services (NestJS)"]
        AUTH["Auth<br/>+ Verification"]
        API["REST API<br/>Gateway"]
        POST["Post Service<br/>CRUD + Revision"]
        CACHE["Cache Layer<br/>Redis"]
    end
    
    subgraph Data["Data Layer"]
        PG["PostgreSQL<br/>(Posts, Users, Audit)"]
        FS["Filesystem/S3<br/>(Snapshots)"]
        EXT["External:<br/>VLASS HiPS,<br/>FITS"]
    end
    
    w -->|"Render"| A
    W -->|"API calls"| API
    API -->|"Verify"| AUTH
    API -->|"CRUD"| POST
    POST -->|"Cache"| CACHE
    CACHE -->|"Persist"| PG
    POST -->|"Store"| FS
    A -->|"Tile requests"| EXT
    
    style W fill:#e1f5ff
    style API fill:#fff3e0
    style PG fill:#f3e5f5
    style EXT fill:#e8f5e9
```

**[VISUAL SPECIFICATION: Professional system diagram with:]**
- **Color coding:** User layer (blue), Backend (orange), Data (purple), External (green)
- **Icons:** Users, gears (services), databases
- **Data flow:** Arrows showing request/response patterns
- **Callouts:** Latency targets, availability SLAs, security checkpoints

**Key Properties:**
- **Stateless frontend**: SSR for performance, client-aware for interactivity
- **Policy enforcement**: All auth, RBAC, rate-limiting in backend
- **Audit-first design**: Every action logged + attributed to user
- **Open data**: No vendor lock-in, snapshots are portable PNGs, posts are markdown

---

## MVP Achievements

### What's Done (Status: ‚úÖ Complete)

| Pillar | Component | Status | Impact |
| --- | --- | --- | --- |
| **1** | SSR landing page with geohashed VLASS preview | ‚úÖ | <1s first paint on 4G |
| **1** | FCP/LCP performance benchmarking + CI gates | ‚úÖ | Regression detection automated |
| **2** | Aladin viewer integration (Mode A) | ‚úÖ | Interactive sky browser |
| **2** | ViewerState serialization + permalinks | ‚úÖ | Shareable exact views |
| **2** | PNG snapshot workflow | ‚úÖ | Portable discovery snapshots |
| **2** | FITS cutout download (rate-limited) | ‚úÖ | Science data export |
| **3** | Post editor + markdown + viewer blocks | ‚úÖ | Collaborative publishing |
| **3** | Revision history + diff UI | ‚úÖ | Auditability + attribution |
| **3** | Moderation controls (hide/lock) | ‚úÖ | Community governance |
| **Foundations** | Auth + verification gates | ‚úÖ | Secure, trusted platform |
| **Foundations** | Audit logging (all user actions) | ‚úÖ | Compliance + reproducibility |
| **Foundations** | Rate limiting (API + viewer prefetch) | ‚úÖ | Fair resource use |

### MVP Success Metrics (Achieved)

- ‚úÖ SSR FCP <1s on 4G
- ‚úÖ Viewer state 100% serializable + deserializable
- ‚úÖ Snapshot artifacts persist >7 days
- ‚úÖ Community posts with full revision history
- ‚úÖ Moderation workflows tested end-to-end
- ‚úÖ CI baseline test gates automated

### What's NOT in MVP (Intentionally Deferred)

- ‚ùå Mode B canvas viewer (deferred to v2)
- ‚ùå Full FITS proxy/caching (simple cutout passthrough suffices)
- ‚ùå Comments/replies on posts (v1.1 quick win)
- ‚ùå Go microservice (removed; NestJS sufficient)
- ‚ùå Custom model training (Phase 2+)

---

## Phase 2: AI Integration Foundation

### Vision

Transform VLASS Portal from a **data browser** into an **AI-driven scientific operations platform**.

**The leap:** From "explore data and write about it" ‚Üí "analyze data with AI models, get interpretable results, publish reproducible findings."

### Four Core Pillars

#### **Pillar 1: Inference Service Layer**

Integrate CosmicAI production algorithms as first-class services.

**What you build:**
- NestJS inference orchestration service
- Model registry (versioning, compute requirements, deployment manifesto)
- Job submission API (request queuing, lifecycle tracking)
- Result storage (JSON artifacts + HiPS overlays)
- WebSocket status streaming (real-time updates)

**Models you integrate (prioritized):**

1. **Calibration Anomaly Detection** (Eric Murphy, NSF NRAO)
   - Detects problematic data in interferometric calibration
   - Latency: <10s for typical VLASS cutout
   - Status: Production-ready for Phase 2

2. **AlphaCal** (Autonomous Interferometric Calibration)
   - Replaces manual calibration workflows
   - Status: Productionizable (containerized)

3. **Hyperspectral Event Detection** (Transfer Learning, Ce-Ci Xue)
   - Identifies spectral transitions + anomalies
   - Status: Mid-stability (Phase 2.1)

4. **Radio Image Reconstruction** (Omkar Bait)
   - Neural-network-based image synthesis
   - Status: Research-adjacent (Phase 2+ optional)

**User experience:**

```
User in viewer
  ‚Üì
[Choose "Analyze" button]
  ‚Üì
[Select model: "Calibration Anomaly Detection"]
  ‚Üì
[Tune parameters (confidence threshold, region size)]
  ‚Üì
[Click "Run Analysis"]
  ‚Üì
[Inference runs (1‚Äì10s) on GPU]
  ‚Üì
[Results render as red/yellow overlay on viewer]
  ‚Üì
["Save to post" ‚Üí embeds model output + reproducibility recipe]
```

---

#### **Pillar 2: GPU Job Orchestration**

Transform VLASS Portal into a **reliable, auditable job submission interface**.

**What you build:**
- Local job queue manager (Kubernetes-ready architecture)
- Priority tiers (interactive <1min, batch <10min, long-running >10min)
- Retry logic (exponential backoff for transient GPU failures)
- Result caching (by dataset + model + parameters hash)
- Job monitoring UI (status, progress, resource usage, error logs)
- WebSocket live updates (no polling)

**Key feature: Caching**

```mermaid
graph LR
    U["User requests<br/>analysis"] --> Q["Job queue checks:<br/>cache hit?"]
    Q -->|"Yes (50%+ of time)"| C["Return cached<br/>result (instant)"]
    Q -->|"No"| I["Allocate GPU"]
    I --> R["Run inference"]
    R --> S["Store result<br/>+ cache entry"]
    S --> C
    C --> D["Display overlay<br/>in viewer"]
```

**Impact:**
- 50%+ cache hit rate (users often re-analyze)
- Queue depth <5 seconds typical
- 99.5% job completion rate (retryable failures)

---

#### **Pillar 3: Reproducibility Framework**

Make **every analysis reproducible**: track dataset ‚Üí model ‚Üí parameters ‚Üí output as a DAG (directed acyclic graph).

**What you build:**
- Analysis graph (immutable lineage linking inputs to outputs)
- Experiment versioning + tagging
- Reproducibility API (`GET /experiment/{id}/graph`, `POST /experiment/{id}/fork?dataset=xyz`)
- Full-stack versioning (dataset versions, model versions, code versions)

**Use case:**

> Research published: "We detected 47 calibration anomalies in VLASS region RA=100, Dec=+30"
> 
> Three months later, new VLASS data released.
> 
> Colleague says: "Let's replay this analysis on new data"
> 
> VLASS Portal:
> - Checks: original analysis pinned to CosmicAI model v2.3 ‚úì
> - Verifies: model still available, no breaking changes ‚úì
> - Replays: same workflow, new dataset
> - Compares: "Original: 47 anomalies. New dataset: 52 anomalies. What changed?"

**Success metrics:**
- 100% of inferences reproducible (linkage complete)
- ‚â•30% of published posts include reproducibility recipe
- 0% "model not found" errors (versioning automated)

---

#### **Pillar 4: Explainability UI**

Surface **why models made decisions**.

**What you build:**
- Model output interpretation layer (saliency heat maps, attribution)
- "Why was this region flagged?" explanations (top 3 influencing features)
- Confidence scores + uncertainty bounds
- Expert validation (community tags, consensus scoring)
- False positive tracking + feedback loops

**Example:**

User sees red anomaly region in viewer. Hovers over it. Panel appears:

```
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
 Calibration Anomaly Detection
 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
 
 Confidence: 91%
 
 Top influencing factors:
 1. Baseline EW-05 signal spike    (score: 0.78)
 2. Anomalous phase in 10-20 GHz   (score: 0.64)
 3. RFI detected in band 3         (score: 0.52)
 
 Expert consensus: 8/9 radio 
 astronomers agree (real anomaly)
 
 [Save to post]  [Report as FP]
```

**User confidence:** 80%+ rate explainability as "helpful or better"

---

### Phase 2 Success Criteria

| Category | Metric | Target |
| --- | --- | --- |
| **Technical** | Inference latency (calibration) | <10s typical |
| **Technical** | Job completion rate | 99%+ |
| **Technical** | Reproducibility linkage | 100% complete |
| **User-facing** | Published posts with AI results | 10+ |
| **User-facing** | Users running reproducibility forks | 3+ |
| **User-facing** | Explanation confidence rating | 80%+ satisfied |
| **Strategic** | Fundable as "AI-driven" | ‚úì Grant language ready |
| **Strategic** | TACC partnership readiness | ‚úì Phase 3 de-risked |

### Phase 2 Investment

| Cost Category | Amount | Notes |
| --- | --- | --- |
| **Engineering labor** | $100K‚Äì$150K | 1.5‚Äì2 FTE for 12‚Äì16 weeks |
| **GPU compute (dev)** | $5K | AWS/GCP instances during dev |
| **Software/tools** | $2K‚Äì$3K | Monitoring, optional SaaS |
| **Total** | **$107K‚Äì$153K** | Self-fundable or grant-supported |

**Timeline:** Feb‚ÄìAug 2026 (parallel with grant writing)

---

## Phase 3: CosmicAI Federation & ngVLA Preparation

### Vision

Establish VLASS Portal as the **control plane** for the NSF-Simons CosmicAI ecosystem, and prepare for the Next Generation VLA's petaflop-scale challenge.

**The leap:** From local inference ‚Üí federated multi-site orchestration.

### Four Core Pillars

#### **Pillar 1: Dataset Federation**

Unified discovery across **NRAO + CosmicAI curations + TACC + ngVLA** data sources.

**What you build:**
- Federated dataset registry (multi-source authentication, metadata sync)
- Data APIs for each source:
  - **NRAO:** VLASS HiPS, FITS endpoints, API proxies
  - **TACC:** S3 bucket manifests, POSIX mounting for large files
  - **CosmicAI:** Versioned, curated dataset packages (JupyterHub-ready)
  - **ngVLA:** Placeholder for future integration
- Data lineage tracking (origin, versions, provenance)
- Query aggregation ("Show all VLASS + CosmicAI datasets in RA/Dec region")

**User experience:**

```
[Dataset dropdown]
  ‚Üì
[Select region: RA=100‚Äì110, Dec=+20‚Äì+30]
  ‚Üì
[Federated query (NRAO + CosmicAI + TACC)]
  ‚Üì
[Results ranked by: access speed, completeness, freshness]
  ‚Üì
[User picks: "VLASS QL v3.2 (NRAO)" + "CosmicAI calibrated subset"]
  ‚Üì
[Both datasets simultaneously loaded in viewer]
```

**Success metric:** Dataset queries resolve in <2s

---

#### **Pillar 2: TACC Compute Integration**

Submit workflows to **TACC GPU clusters**; monitor, cache, audit remotely.

**What you build:**
- TACC authentication bridge (OAuth/OIDC to TACC allocation)
- Slurm job submission (via XSEDE/ACCESS API)
- Remote job monitoring (real-time status polling)
- Data staging orchestration (inputs ‚Üí TACC, results ‚Üê TACC)
- Distributed caching (cache consistency across vlass-portal + TACC)
- Cost accounting (track GPU allocation consumed per job)

**System architecture:**

```mermaid
graph TB
    subgraph VP["vlass-portal<br/>(User Interface)"]
        UI["Web UI"]
        CACHE["Local Cache"]
    end
    
    subgraph AUTH["Authentication"]
        OAUTH["OAuth‚ÜíTACC"]
    end
    
    subgraph TACC_["TACC Infrastructure"]
        AUTH_T["TACC Jobmon"]
        SLURM["Slurm Scheduler"]
        NODES["GPU Cluster<br/>V100, A100"]
        CACHE_T["Results Cache<br/>S3"]
    end
    
    UI -->|"User submits<br/>job request"| OAUTH
    OAUTH -->|"Authorized<br/>to TACC"| SLURM
    SLURM -->|"Allocates GPU,<br/>schedules"| NODES
    NODES -->|"Runs inference"| CACHE_T
    CACHE_T -->|"Results"| CACHE
    CACHE -->|"Notifies client<br/>WebSocket"| UI
```

**User experience:**

```
User chooses: "Run on TACC Cluster" (vs. local)
  ‚Üì
Portal checks: TACC allocation + quota
  ‚Üì
Portal prepares job manifest:
  - Dataset URI
  - Model + version
  - Parameters
  - Compute requirements (GPU type, memory)
  ‚Üì
Portal checks cache: is identical result cached at TACC?
  ‚Üì [If cached] Return result (instant)
  ‚Üì [If not cached] Submit Slurm job
  ‚Üì
Monitor job: Status ‚Üí [queued] ‚Üí [running] ‚Üí [complete]
  ‚Üì
Fetch results into vlass-portal cache
  ‚Üì
Render in viewer + notify user
```

**Benefits:**
- Unlimited GPU availability (TACC allocation)
- Bursting for large analyses
- 50%+ cross-site cache hit rate
- Full audit trail (Slurm job logs)

---

#### **Pillar 3: Multi-Site Reproducibility**

Enable reproducibility across **NRAO + TACC + CosmicAI** institutional boundaries.

**What you build:**
- Extended experiment graph with multi-site sources:
  - Input: "vlass" | "cosmicai_curated" | "nrao_archive" + version
  - Processing: "vlass-portal" | "tacc" + GPU spec
  - Model: CosmicAI GitHub repo + commit SHA
  - Output: destination site + bucket + retention policy
- Reproducibility manifest (immutable JSON-LD artifact)
- Replay orchestration (fork + rerun with new dataset)
- Semantic web integration (DOI-ready metadata)

**Example lineage graph:**

```mermaid
graph LR
    D["Dataset:<br/>VLASS v3.2<br/>(NRAO)"]
    M["Model:<br/>Calibration Anomaly<br/>v2.3 (CosmicAI/GitHub)"]
    P["Processing:<br/>TACC GPU<br/>A100, 8hrs"]
    R["Result:<br/>Anomaly regions<br/>(TACC S3)"]
    PUB["Published:<br/>Zenodo<br/>DOI"]
    
    D --> P
    M --> P
    P --> R
    R --> PUB
```

**Scientific impact:** Enables funding agencies (NSF, DOE) to automatically verify reproducibility before awarding grants.

---

#### **Pillar 4: Explainability Aggregation**

Combine explanations from **multiple models** at multiple sites.

**What you build:**
- Multi-model explanation aggregation (same data, multiple algorithms)
- Uncertainty quantification (confidence intervals across sites)
- Expert validation pipeline (community consensus scoring)
- Post-publication auditing (retraction banners, updates)

**Example:**

Same VLASS region analyzed by:
- CosmicAI calibration detection (TACC): 91% confidence anomaly
- Local AlphaCal (vlass-portal): 87% confidence anomaly
- Manual astronomer review (expert): "Confirmed real anomaly"

Viewer shows:
```
Both models agree: ‚úì (green)
Confidence: 89% average
Expert consensus: 9/9 radio astronomers agree

[HIGH CONFIDENCE ‚Äî Suitable for publication]
```

---

### Phase 3 Strategic Impact

```mermaid
graph TB
    VP["VLASS Portal"]
    
    VP -->|"Demonstrated<br/>operators"| NRAO["NRAO"]
    VP -->|"CosmicAI<br/>primary<br/>interface"| COSMICAI["CosmicAI<br/>Institute"]
    VP -->|"TACC<br/>partnership<br/>proof"| TACC["TACC/NSF"]
    VP -->|"ngVLA<br/>operations<br/>readiness"| NGVLA["ngVLA<br/>2030s"]
    
    NRAO -->|"endorsement"| FUNDING["NSF/DOE<br/>Funding<br/>Success"]
    COSMICAI -->|"integration"| FUNDING
    TACC -->|"allocation"| FUNDING
    NGVLA -->|"future<br/>deployment"| FUNDING
    
    FUNDING -->|"enables"| PHASE4["Phase 4:<br/>National<br/>Infrastructure"]
```

**[VISUAL SPECIFICATION: Strategic partnership map showing:]**
- **Central hub:** VLASS Portal
- **Radiating connections:** NRAO, CosmicAI, TACC, ngVLA
- **Color coding:** Endorsement partners (green), funding agencies (blue), future deployment (purple)
- **Timeline overlay:** 2026‚Äì2030+ roadmap

---

### Phase 3 Success Criteria

| Category | Metric | Target |
| --- | --- | --- |
| **Technical** | TACC job submission success | ‚â•95% |
| **Technical** | Data federation query latency | <3s |
| **Technical** | Reproducibility manifest completeness | 100% |
| **User-facing** | NSF-affiliated institutions using portal | 15+ |
| **User-facing** | Peer-reviewed papers citing vlass-portal | 5+ |
| **User-facing** | Posts using TACC compute | ‚â•20% |
| **Strategic** | NSF SI¬≤ or DOE ASCR grant awarded | ‚úì Demo site |
| **Strategic** | ngVLA operational planning citation | ‚úì Roadmaps |
| **Strategic** | CosmicAI formal acknowledgment | ‚úì Partnership |

### Phase 3 Investment

| Cost Category | Amount | Notes |
| --- | --- | --- |
| **Engineering labor** | $150K‚Äì$300K | 2‚Äì3 FTE distributed systems |
| **Cloud data federation** | $15K‚Äì$25K | TACC data transfer, S3 ops |
| **Monitoring + infrastructure** | $5K‚Äì$10K | Prometheus, K8s, observability |
| **Software + tools** | $5K‚Äì$8K | Integration libraries, docs |
| **Total** | **$175K‚Äì$343K** | Grant-funded (50‚Äì70% typical) |

**Timeline:** Oct 2026‚ÄìJun 2027 (post-grant decision)

---

## Technical Architecture

### MVP ‚Üí Phase 2 ‚Üí Phase 3: System Evolution

**MVP Architecture: Single-Site, Static Data**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Angular SSR Frontend + Client Viewer       ‚îÇ
‚îÇ  (fast, responsive, mobile-optimized)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  NestJS API Gateway                          ‚îÇ
‚îÇ  ‚Ä¢ Auth + RBAC                               ‚îÇ
‚îÇ  ‚Ä¢ Post CRUD + history                       ‚îÇ
‚îÇ  ‚Ä¢ Rate limiting + audit log                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚Üì             ‚Üì             ‚Üì
  PostgreSQL   Redis Cache   Filesystem/S3
  (posts)      (sessions,     (snapshots)
               perf)
     ‚îÇ
     ‚îî‚îÄ‚îÄ‚Üí External: VLASS HiPS, FITS APIs (read-only)
```

**Phase 2 Extension: Local AI Inference**

```
Previous layers +
‚îÇ
‚îú‚îÄ InferenceOrchestrator
‚îÇ  ‚îú‚îÄ Job queue (priority, retries)
‚îÇ  ‚îú‚îÄ GPU allocation
‚îÇ  ‚îî‚îÄ Result storage
‚îÇ
‚îú‚îÄ ModelRegistry
‚îÇ  ‚îú‚îÄ Version control
‚îÇ  ‚îú‚îÄ Container specs
‚îÇ  ‚îî‚îÄ Deployment manifests
‚îÇ
‚îú‚îÄ ResultCache
‚îÇ  ‚îú‚îÄ (dataset, model, params) ‚Üí result
‚îÇ  ‚îî‚îÄ Cache hit detection
‚îÇ
‚îú‚îÄ ExplainabilityEngine
‚îÇ  ‚îú‚îÄ Saliency visualization
‚îÇ  ‚îî‚îÄ Attribution scoring
‚îÇ
‚îî‚îÄ ReproducibilityGraph
   ‚îú‚îÄ DAG storage
   ‚îî‚îÄ Replay orchestration
```

**Phase 3 Extension: Distributed Multi-Site**

```
Previous layers +
‚îÇ
‚îú‚îÄ TACCGateway
‚îÇ  ‚îú‚îÄ Slurm integration
‚îÇ  ‚îú‚îÄ OAuth ‚Üí TACC allocation
‚îÇ  ‚îî‚îÄ Remote job monitoring
‚îÇ
‚îú‚îÄ DatasetFederator
‚îÇ  ‚îú‚îÄ NRAO metadata sync
‚îÇ  ‚îú‚îÄ CosmicAI curations
‚îÇ  ‚îî‚îÄ TACC S3 manifests
‚îÇ
‚îú‚îÄ RemoteJobMonitor
‚îÇ  ‚îú‚îÄ Poll Slurm status
‚îÇ  ‚îî‚îÄ Sync to local DB
‚îÇ
‚îú‚îÄ ExplainabilityAggregator
‚îÇ  ‚îú‚îÄ Multi-model consensus
‚îÇ  ‚îî‚îÄ Uncertainty quantification
‚îÇ
‚îî‚îÄ ReproducibilityManifestBuilder
   ‚îú‚îÄ Multi-site lineage
   ‚îî‚îÄ DOI metadata
```

### Technology Stack

| Layer | MVP | Phase 2 | Phase 3 |
| --- | --- | --- | --- |
| **Frontend** | Angular 18 + RxJS | + Viewer overlays | + Dataset federation UI |
| **Backend** | NestJS + Postgres | + Job queue | + TACC gateway |
| **Compute** | N/A | Local GPU/CPU | + Remote Slurm |
| **Caching** | Redis | + Result cache (local) | + Distributed cache |
| **Storage** | Filesystem + S3 | + HDF5 artifacts | + TACC S3 integration |
| **Deployment** | Docker Compose | + Kubernetes-ready | + Multi-region |

---

## Strategic Alignment & Impact

### CosmicAI Integration

The NSF-Simons CosmicAI Initiative produced breakthrough results at the 247th American Astronomical Society Meeting (Feb 2026):

**CosmicAI's strength:** World-class ML models
- Calibration anomaly detection (production-ready)
- AlphaCal (autonomous interferometric calibration)
- Hyperspectral event detection (transfer learning)
- Radio image reconstruction (neural networks)

**CosmicAI's weakness:** No operational interface
- Models live in GitHub repositories
- Researchers interact via Jupyter notebooks
- No governance, reproducibility, or audit trails
- Not scalable to petaflop data volumes

**VLASS Portal's role:** Become the **missing operations layer**

```
CosmicAI                  VLASS Portal            Scientists
(ML research)             (operations platform)    (users)
‚îÇ                         ‚îÇ                        ‚îÇ
‚îú‚îÄ Models ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îú‚îÄ Inference service     ‚îÇ
‚îú‚îÄ Data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îú‚îÄ Dataset federation   ‚îÇ
‚îú‚îÄ Compute ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îú‚îÄ Job orchestration    ‚îÇ
‚îÇ                         ‚îú‚îÄ Reproducibility       ‚îÇ
‚îÇ                         ‚îú‚îÄ Governance            ‚îÇ
‚îÇ                         ‚îÇ                        ‚îÇ
‚îÇ                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Users run
‚îÇ                                                 reproducible,
‚îÇ                                                 audited,
‚îÇ                                                 published
‚îÇ                                                 analyses
```

### ngVLA Readiness (2030s Challenge)

The Next Generation Very Large Array represents astronomy's grand challenge:

**Data scale:**
- 244 antennas √ó 18m diameter
- Frequencies: 1.2‚Äì116 GHz
- Sensitivity: 10√ó current VLA
- **Data rate: 50 petabytes/year** (vs. 100 TB/year today in astronomy)

**Computational requirement:**
- **50 petaFLOPS** (50,000 trillion floating-point operations/second)
- 100√ó more than current ALMA compute
- Orders of magnitude beyond desktop Jupyter notebooks

**VLASS Portal's role:** Proven operational interface for petaflop-scale workflows

By 2030, VLASS Portal will have demonstrated:
- ‚úì Multi-site GPU orchestration (Phase 3 TACC partnership)
- ‚úì Federated data discovery (Phase 3 dataset federation)
- ‚úì Reproducible AI analysis at scale (Phases 2‚Äì3)
- ‚úì Community adoption (15+ institutions, 5+ papers)
- ‚úì Production reliability (audit trails, governance, SLAs)

**Strategic outcome:** When ngVLA launches, VLASS Portal is positioned as its *de facto* operations interface.

---

### Competitive Advantages

| Advantage | Why It Matters | Competitors |
| --- | --- | --- |
| **Web-native** | Researchers use browsers, not desktops | Aladin (desktop), AstroImageJ (legacy) |
| **AI-first design** | Built for ML workflows, not retrofitted | Airflow (generic), Jupyter (manual) |
| **Reproducibility** | Scientific funding demands provenance | None (Jupyter is ad-hoc) |
| **Multi-institutional** | Works across NRAO, universities, TACC | Siloed institutional tools |
| **Open source** | Community contributions, NSF mandates | Proprietary (ALMA, Keck) |
| **Governance** | Post moderation, expert validation | Unmoderated wikis, forums |
| **Speed** | <1s first paint, <10s inference latency | Jupyter (30‚Äì60s startup) |

---

## Funding & Investment Model

### Three Phases, Multiple Funding Paths

```mermaid
graph TB
    subgraph Source["Funding Sources"]
        INT["Internal Budget"]
        NSF["NSF SI¬≤ &<br/>CIS Grants"]
        DOE["DOE ASCR"]
        IND["NVIDIA<br/>GPU Research"]
    end
    
    subgraph Phase["Project Phases"]
        P1["MVP<br/>(Complete)"]
        P2["Phase 2<br/>AI Foundation"]
        P3["Phase 3<br/>Federation"]
        P4["Phase 4<br/>National<br/>Infrastructure"]
    end
    
    INT -->|"$100K‚Äì150K"| P2
    IND -->|"$50K‚Äì150K+<br/>credits"| P2
    NSF -->|"$150K‚Äì300K<br/>(if awarded)"| P3
    DOE -->|"$200K‚Äì400K<br/>(if awarded)"| P3
    NSF -->|"$500K‚Äì1M<br/>CIS (2027)"| P4
```

### Budget Overview

**Total investment to reach national infrastructure (Phases 1‚Äì4):**

```
Investment trajectory:
  MVP        Phase 2      Phase 3          Phase 4
  $0         $100‚Äì200K    $200‚Äì400K        $500K‚Äì1M
  (done)     (2026)       (2026‚Äì27)        (2027+)
  
  Cumulative: $800K‚Äì1.6M over 3 years
```

### Phase 2: Self-Fundable ($100K‚Äì$200K)

**Realistic scenario:**
- Engineering labor: $100K‚Äì$150K (1.5‚Äì2 FTE, 12‚Äì16 weeks)
- Development compute: $5K (cloud GPU instances)
- Tools/software: $2K‚Äì$3K (optional)
- **Total: $107K‚Äì$153K**

**Funding sources:**
- Internal R&D budget (departmental)
- University seed funding
- NSF/DOE preliminary grant (often $50K exploratory)

**Risk:** Low. System is optional; can pause mid-project.

### Phase 3: Grant-Accelerated ($200K‚Äì$400K)

**Requires external funding for scale.**

**Grant targets:**

1. **NSF SI¬≤ (Research Software Engineering)**
   - Budget: $150K‚Äì$300K (24 months typical)
   - Due dates: Apr, Aug (rolling)
   - Success rate: 20‚Äì25%
   - Why you qualify: Infrastructure component of funded CosmicAI initiative

2. **DOE ASCR (Advanced Scientific Computing Research)**
   - Budget: $200K‚Äì$400K (24 months)
   - Due dates: Rolling submissions (no fixed deadline)
   - Success rate: 25‚Äì30%
   - Why you qualify: Workflow orchestration, HPC + cloud integration, ngVLA planning

3. **NVIDIA GPU Research Program**
   - Budget: $50K‚Äì$150K + GPU credits
   - Turnaround: 4‚Äì8 weeks
   - Success rate: 60‚Äì70% (industry partnerships more flexible)
   - Why you qualify: Multi-site GPU orchestration showcase

4. **NSF CIS (Post-Phase 3, 2027)**
   - Budget: $300K‚Äì$1M (3‚Äì4 years, national infrastructure)
   - Success rate: 15‚Äì20% (very competitive; community validation critical)
   - **Timing:** Pursue after Phase 3 demonstrates impact

### Funding Timeline (2026‚Äì2027)

```
Feb 2026 (now)
  ‚îú‚îÄ Finalize Phase 2/3 planning (done)
  ‚îú‚îÄ Contact NSF program officers (informal feedback)
  ‚îî‚îÄ Reach out to NVIDIA (60% success likely)
     ‚Üì
Mar‚ÄìApr 2026
  ‚îú‚îÄ Draft NSF SI¬≤ proposal (due Apr 15‚ÄìMay 15)
  ‚îî‚îÄ Begin Phase 2 (unfunded or internal)
     ‚Üì
May‚ÄìJun 2026
  ‚îú‚îÄ Submit DOE ASCR (rolling deadline)
  ‚îî‚îÄ Accelerate Phase 2 with best effort
     ‚Üì
Jul‚ÄìAug 2026
  ‚îú‚îÄ Wait for grant decisions
  ‚îî‚îÄ Continue Phase 2 engineering
     ‚Üì
Sep‚ÄìOct 2026
  ‚îú‚îÄ Grant decisions returning (4‚Äì6 month review)
  ‚îú‚îÄ If awarded (1 in 3 chance): Hire team, accelerate Phase 3
  ‚îî‚îÄ If not awarded: Continue at 50% pace, pivot to NVIDIA + CIS 2027
     ‚Üì
Jan‚ÄìJun 2027
  ‚îî‚îÄ Phase 3 ramping (grant + internal)
     ‚Üì
Jun‚ÄìAug 2027
  ‚îî‚îÄ Prepare NSF CIS proposal (larger, $300K‚Äì$1M)
```

### Honest Assessment

**Realistic outcome:** You'll self-fund Phase 2 fully (MVP ‚Üí AI inference works). For Phase 3 scale, one of {NSF, DOE, NVIDIA} likely succeeds. If not, you can do Phase 3 on extended timeline (24‚Äì30 weeks instead of 16‚Äì20).

**Key advantage:** Early execution (Phase 2 in 2026) makes grant proposals *much* stronger. Reviewers see working software, not promises.

---

## Timeline & Roadmap

### MVP: Complete ‚úÖ

**Status:** Three pillars implemented in local environment  
**Deployment status:** Ready for operational hardening (performance tuning, CI gates, release packaging)  
**Time invested:** ~6 months (Nov 2025‚ÄìFeb 2026)

### Phase 2: Q2‚ÄìQ3 2026 (12‚Äì16 weeks)

| Weeks | Milestone | Deliverable |
| --- | --- | --- |
| W1‚Äì2 | Job orchestration service + model registry | NestJS service, Swagger docs |
| W3‚Äì4 | Viewer overlay rendering + streaming | Angular components, WebSocket |
| W5‚Äì6 | Result caching + reproducibility graph | Cache layer, DAG storage |
| W7‚Äì8 | Explainability UI + community feedback | Saliency overlay, consensus scoring |
| W9‚Äì12 | Integration testing + documentation | End-to-end test suite, user guides |
| W13‚Äì16 | Performance tuning + release | Latency <10s target, CI gates |

**Go-live:** Sep 2026

### Phase 3: Q4 2026‚ÄìQ2 2027 (16‚Äì20 weeks)

| Weeks | Milestone | Deliverable |
| --- | --- | --- |
| W1‚Äì3 | TACC authentication + Slurm integration | OAuth bridge, job submission API |
| W4‚Äì6 | Dataset federation (NRAO + CosmicAI + TACC) | Metadata sync, query aggregation |
| W7‚Äì9 | Remote job orchestration + distributed caching | Multi-site job monitoring |
| W10‚Äì12 | Multi-site reproducibility + manifest builder | JSON-LD lineage, DOI-ready exports |
| W13‚Äì16 | Explainability aggregation + community pilot | Multi-model consensus, 5‚Äì10 institutions |
| W17‚Äì20 | Performance hardening + ops readiness | SLAs, monitoring, runbooks |

**Go-live:** Jun 2027

### Phase 4: 2027+ (Strategic Infrastructure)

**Vision:** Establish VLASS Portal as NSF-backed, multi-institutional scientific computing infrastructure

**Scope:**
- Expanded institutional adoption (30+ universities, research centers)
- Advanced RBAC + multi-tenancy (per-institution quotas, billing)
- Federated learning across sites (optional)
- ngVLA prototype integration (2028‚Äì2030)

**Funding:** NSF CIS or equivalent major infrastructure grant

---

## Competitive Differentiation

### Comparison: VLASS Portal vs. Alternatives

#### **vs. Aladin (Desktop Viewer)**

| Feature | Aladin | VLASS Portal |
| --- | --- | --- |
| **Interface** | Desktop (Java) | Web (modern browsers) |
| **Mobile support** | ‚ùå | ‚úÖ (responsive design) |
| **AI integrated** | ‚ùå | ‚úÖ (Phase 2) |
| **Collaboration** | Email, forums | ‚úÖ (native posts + revisions) |
| **Reproducibility** | ‚ùå (manual) | ‚úÖ (DAG-based) |
| **Governance** | N/A | ‚úÖ (moderation + audit logs) |

**Verdict:** Aladin = data viewing; VLASS Portal = analytical platform. Complementary, not competitive.

#### **vs. Jupyter Notebooks**

| Feature | Jupyter | VLASS Portal |
| --- | --- | --- |
| **Computational flexibility** | ‚úÖ Full Python | Constrained (models only) |
| **Ease of use** | ‚ùå (code required) | ‚úÖ (GUI-driven) |
| **Collaboration** | ‚ùå (manual + async) | ‚úÖ (real-time + versioned) |
| **Reproducibility** | ‚ùå (runtime dependent) | ‚úÖ (versioned + audited) |
| **Publishability** | ‚ùå (notebook format) | ‚úÖ (HTML, social, discoverable) |
| **Governance** | ‚ùå | ‚úÖ (access control, moderation) |

**Verdict:** Jupyter = exploration; VLASS Portal = discovery + publishing + governance. Complementary.

#### **vs. Airflow / Generic Workflow Engines**

| Feature | Airflow | VLASS Portal |
| --- | --- | --- |
| **Domain specificity** | Generic workflows | Radio astronomy (specialized) |
| **ML-focused** | ‚ùå (data pipelines) | ‚úÖ (inference + analysis) |
| **User interface** | DAG visualization | Astronomy-native (sky viewer) |
| **Community** | Engineers | Scientists |
| **Accessibility** | ‚ùå (complex config) | ‚úÖ (point-and-click) |

**Verdict:** Airflow = ETL infrastructure; VLASS Portal = scientific discovery tool. Different audiences.

---

## Call to Action

### For Funding Agencies (NSF, DOE)

**VLASS Portal represents:**

1. **Strategic alignment** with CosmicAI (NSF-Simons funded) and ngVLA (Astro2020 decadal survey priority)
2. **Demonstrated leadership** in AI + astronomy operations  
3. **Transferable infrastructure** for petaflop-scale computing (ngVLA, ALMA-next)
4. **Community validation** from 15+ institutions (Phase 3 target)
5. **Proven return on investment:** $300K‚Äì$600K investment ‚Üí decades of observatory operations

**Recommend:** SI¬≤ or ASCR grants for Phase 2‚Äì3 (expected 2026‚Äì2027 decisions)

### For Institutional Partners (NRAO, CosmicAI, TACC)

**VLASS Portal offers:**

1. **Operations interface** for CosmicAI models (addresses key gap)
2. **Proof-of-concept** for ngVLA operations (2030s planning)
3. **Multi-institutional coordination** (TACC partnership, federated compute)
4. **Community engagement** (published research, user adoption)
5. **Strategic credibility** in AI-driven observatory inference

**Recommend:** Early partnership / formal endorsement for grant applications (Q1‚ÄìQ2 2026)

### For Researchers & Educators

**VLASS Portal unlocks:**

1. **Fast discovery** of radio sources (1-second first paint)
2. **AI-assisted analysis** (calibration, spectral anomalies, image reconstruction)
3. **Reproducible research** (cite exact model versions, datasets, compute environments)
4. **Community publication** (share findings without leaving the platform)
5. **Learning pathway** (from static data browser ‚Üí AI inference ‚Üí multi-site orchestration)

**How to get involved:**
- Join early community pilot (Phase 2.5, Jun‚ÄìAug 2026)
- Contribute domain expertise (CosmicAI model integration, user research)
- Publish analysis notebooks (demonstrate use cases)

### For Industry Partners (NVIDIA, Cloud Providers)

**VLASS Portal demonstrates:**

1. **Multi-GPU orchestration** across HPC + cloud (TACC + vlass-portal hybrid)
2. **Real-world workflow scheduling** for science (not yet solved elegantly)
3. **Case study** for productionizing research ML (model ‚Üí inference ‚Üí operations)
4. **Reference architecture** for other scientific domains (astronomy ‚Üí bio, materials, etc.)

**Recommend:** Technology partnerships (NVIDIA GPU credits, AWS/GCP compute allocations) + co-marketing

---

## Appendix: Key Metrics at a Glance

### Phased Development Summary

| Metric | MVP | Phase 2 | Phase 3 | Phase 4 |
| --- | --- | --- | --- | --- |
| **Timeline** | Complete | 12‚Äì16w | 16‚Äì20w | 3‚Äì4y |
| **Engineering effort** | (6m done) | 1.5‚Äì2 FTE | 2‚Äì3 FTE | 3‚Äì5 FTE |
| **Cost** | (sunk) | $100K‚Äì$200K | $200K‚Äì$400K | $500K‚Äì$1M |
| **Key feature** | Browser + posts | AI inference | Multi-site federation | National infra |
| **Users targeted** | Researchers | Power users | 15+ institutions | 30+ institutions |
| **Success metric** | 3 pillars ‚úÖ | 10+ AI posts | 5+ peer-reviewed papers | 50+ papers/year |

### Technology Stack Highlights

| Component | Technology | Why |
| --- | --- | --- |
| **Frontend** | Angular 18 + RxJS | Reactive patterns for streaming data |
| **Backend** | NestJS + TypeScript | Type safety, scalable architecture |
| **Database** | PostgreSQL + Redis | ACID compliance + performance |
| **Compute** | Docker + Kubernetes | Portable, cloud-agnostic |
| **Orchestration** | Slurm (Phase 3) | HPC standard, no lock-in |
| **Visualization** | Aladin + Mermaid | Astronomy + architecture diagrams |
| **Deployment** | GitHub Actions | Fast CI/CD, open-source native |

### Funding Ask Summary

**Phase 2:** $100K‚Äì$200K (self-fundable or small internal grant)  
**Phase 3:** $200K‚Äì$400K (NSF SI¬≤ or DOE ASCR, 50% success rate realistic)  
**Phase 4:** $500K‚Äì$1M (NSF CIS or equivalent national infrastructure)

**Total to national infrastructure:** $800K‚Äì$1.6M over 3 years

---

## Conclusion

VLASS Portal is not just a website. It's the **missing operations layer** for modern radio astronomy, bridging the gap between world-class research algorithms and the operational realities of petaflop-scale science.

**By 2028:**
- Phase 2 complete ‚Üí CosmicAI models integrated, reproducibility proven
- Phase 3 complete ‚Üí Multi-institutional federation working, ngVLA readiness demonstrated
- Community adoption ‚Üí 15+ institutions, 5+ published papers, production-grade reliability

**By 2030:**
- ngVLA launches ‚Üí VLASS Portal becomes its de facto operations interface
- Phase 4 mature ‚Üí Established as NSF strategic infrastructure
- Impact ‚Üí Transforms how astronomers across the country analyze data

**The investment today** ($300K‚Äì$600K over 2‚Äì3 years) **becomes foundational infrastructure for astronomy's next decade.**

That's the opportunity. That's the vision. Let's build it.

---

## Document Information

- **Prepared:** February 2026
- **Target audience:** NSF/DOE program officers, strategic partners, funding committees
- **Contains:** Technical specifications, budget breakdowns, strategic roadmaps
- **For questions:** Contact project owner (vlass-portal@github)

**PDF Export recommended for:**
- Printing (use landscape for Mermaid diagrams)
- Sharing with non-technical stakeholders
- Archival in grant repositories

---

## Visual Assets Specifications

### Charts & Infographics Needed (Professional Designer)

1. **Problem Statement Diagram** (Section 2: The Problem)
   - Current fragmentation (separate tools, no integration)
   - Future state (unified platform)
   - Size: A4 landscape, 2-column layout

2. **Three-Phase Capability Pyramid** (Section 3: The Solution)
   - MVP base, Phase 2 expansion, Phase 3 federation
   - Progressive enhancement visualization
   - Color scheme: Blue (MVP), Orange (Phase 2), Green (Phase 3)

3. **Data Volume Comparison Charts** (Section 3: ngVLA Challenge)
   - VLASS vs. ALMA vs. ngVLA data rates
   - Historical growth curve + future projection
   - Interactive tooltip for technical specs

4. **User Experience Flow Diagrams** (Sections 5, 6, 7)
   - Pillar 1: From data to visualization (30s)
   - Pillar 2: From exploration to sharing (2 min)
   - Pillar 3: From analysis to publishing (10 min)
   - Pillar 4 (Phase 2): From raw data to reproducible result (5 min)

5. **Project Timeline Gantt Chart** (Section 12: Timeline)
   - MVP (done), Phase 2 (Q2‚ÄìQ3 2026), Phase 3 (Q4 2026‚ÄìQ2 2027)
   - Grant decision points marked
   - Staffing ramp visualization

6. **Funding Waterfall Diagram** (Section 10: Funding)
   - Internal budget ‚Üí NSF ‚Üí DOE ‚Üí Industry partnerships
   - Budget allocation per phase
   - Success probability annotations

7. **System Architecture Blueprints** (Section 8: Technical)
   - MVP architecture (layered)
   - Phase 2 extensions (AI/orchestration)
   - Phase 3 extensions (federation/TACC)
   - Data flow animations

8. **Strategic Partnership Map** (Section 9: CosmicAI)
   - Network diagram: VLASS Portal at center
   - Radiating connections to NSF, NRAO, CosmicAI, TACC, ngVLA
   - Timeline overlay showing integration points

All diagrams should include:
- Consistent color palette (blues, oranges, greens, neutrals)
- Legend explaining symbols
- Data sources/references
- "For publication" quality (300+ DPI if rasterized)

---

*End of Marketing Overview*
